{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_train = pd.read_csv('UnScaled Data_train.csv')\n",
    "read_test = pd.read_csv('UnScaled Data_test.csv')\n",
    "\n",
    "\n",
    "read_train = read_train.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "read_test = read_test.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "\n",
    "target = pd.read_csv('train_target.csv')\n",
    "target = target.drop('0', axis = 1)\n",
    "update_target= [1]\n",
    "\n",
    "\n",
    "unique_id = pd.read_csv('test_unique_id.csv')\n",
    "unique_id = unique_id.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "unique_id['bank_account'] = approximate_data\n",
    "\n",
    "\n",
    "for k in target['1']:\n",
    "    update_target.append(k)\n",
    "targ = np.array(update_target)\n",
    "targ.shape\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "target = target.astype('int')\n",
    "x_train, x_test,y_train, y_test = train_test_split(read_train, targ, train_size = 0.8, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 20\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 1\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "momentum=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.Session() as sess:\n",
    "init.run()\n",
    "for epoch in range(n_epochs):\n",
    "for iteration in range(mnist.train.num_examples // batch_size):\n",
    "X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "sess.run([training_op, extra_update_ops],\n",
    "feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "y: mnist.test.labels})\n",
    "print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_id.to_csv('keras_one.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
