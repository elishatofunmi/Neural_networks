{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Train_v2.csv')\n",
    "test_data = pd.read_csv('Test_v2.csv')\n",
    "variable_defination = pd.read_csv('VariableDefinitions.csv')\n",
    "Submission_file = pd.read_csv('SubmissionFile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country = train_data['country']\n",
    "test_country = test_data['country']\n",
    "\n",
    "test_id = test_data['uniqueid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>bank_account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uniqueid_7867 x Kenya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uniqueid_6722 x Kenya</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniqueid_6714 x Kenya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uniqueid_8103 x Kenya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uniqueid_8657 x Kenya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                uniqueid  bank_account\n",
       "0  uniqueid_7867 x Kenya           1.0\n",
       "1  uniqueid_6722 x Kenya           0.0\n",
       "2  uniqueid_6714 x Kenya           1.0\n",
       "3  uniqueid_8103 x Kenya           1.0\n",
       "4  uniqueid_8657 x Kenya           1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10086 entries, 0 to 10085\n",
      "Data columns (total 12 columns):\n",
      "country                   10086 non-null object\n",
      "year                      10086 non-null int64\n",
      "uniqueid                  10086 non-null object\n",
      "location_type             10086 non-null object\n",
      "cellphone_access          10086 non-null object\n",
      "household_size            10086 non-null int64\n",
      "age_of_respondent         10086 non-null int64\n",
      "gender_of_respondent      10086 non-null object\n",
      "relationship_with_head    10086 non-null object\n",
      "marital_status            10086 non-null object\n",
      "education_level           10086 non-null object\n",
      "job_type                  10086 non-null object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 945.6+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>bank_account</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_2</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>No formal education</td>\n",
       "      <td>Government Dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other relative</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Vocational/Specialised training</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_4</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Formally employed Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_5</td>\n",
       "      <td>No</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Child</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Informally employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year    uniqueid bank_account location_type cellphone_access  \\\n",
       "0   Kenya  2018  uniqueid_1          Yes         Rural              Yes   \n",
       "1   Kenya  2018  uniqueid_2           No         Rural               No   \n",
       "2   Kenya  2018  uniqueid_3          Yes         Urban              Yes   \n",
       "3   Kenya  2018  uniqueid_4           No         Rural              Yes   \n",
       "4   Kenya  2018  uniqueid_5           No         Urban               No   \n",
       "\n",
       "   household_size  age_of_respondent gender_of_respondent  \\\n",
       "0               3                 24               Female   \n",
       "1               5                 70               Female   \n",
       "2               5                 26                 Male   \n",
       "3               5                 34               Female   \n",
       "4               8                 26                 Male   \n",
       "\n",
       "  relationship_with_head           marital_status  \\\n",
       "0                 Spouse  Married/Living together   \n",
       "1      Head of Household                  Widowed   \n",
       "2         Other relative     Single/Never Married   \n",
       "3      Head of Household  Married/Living together   \n",
       "4                  Child     Single/Never Married   \n",
       "\n",
       "                   education_level                   job_type  \n",
       "0              Secondary education              Self employed  \n",
       "1              No formal education       Government Dependent  \n",
       "2  Vocational/Specialised training              Self employed  \n",
       "3                Primary education  Formally employed Private  \n",
       "4                Primary education        Informally employed  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23524 entries, 0 to 23523\n",
      "Data columns (total 13 columns):\n",
      "country                   23524 non-null object\n",
      "year                      23524 non-null int64\n",
      "uniqueid                  23524 non-null object\n",
      "bank_account              23524 non-null object\n",
      "location_type             23524 non-null object\n",
      "cellphone_access          23524 non-null object\n",
      "household_size            23524 non-null int64\n",
      "age_of_respondent         23524 non-null int64\n",
      "gender_of_respondent      23524 non-null object\n",
      "relationship_with_head    23524 non-null object\n",
      "marital_status            23524 non-null object\n",
      "education_level           23524 non-null object\n",
      "job_type                  23524 non-null object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Kenya', 'Rwanda', 'Tanzania', 'Uganda'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_data['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_update = pd.get_dummies(train_data, columns = ['country'])\n",
    "test_update = pd.get_dummies(test_data, columns = ['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23524 entries, 0 to 23523\n",
      "Data columns (total 16 columns):\n",
      "year                      23524 non-null int64\n",
      "uniqueid                  23524 non-null object\n",
      "bank_account              23524 non-null object\n",
      "location_type             23524 non-null object\n",
      "cellphone_access          23524 non-null object\n",
      "household_size            23524 non-null int64\n",
      "age_of_respondent         23524 non-null int64\n",
      "gender_of_respondent      23524 non-null object\n",
      "relationship_with_head    23524 non-null object\n",
      "marital_status            23524 non-null object\n",
      "education_level           23524 non-null object\n",
      "job_type                  23524 non-null object\n",
      "country_Kenya             23524 non-null uint8\n",
      "country_Rwanda            23524 non-null uint8\n",
      "country_Tanzania          23524 non-null uint8\n",
      "country_Uganda            23524 non-null uint8\n",
      "dtypes: int64(3), object(9), uint8(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2016, 2017, 2018], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "train_update['year'][train_update['year']==2016] = 0\n",
    "train_update['year'][train_update['year'] == 2017] = 1\n",
    "train_update['year'][train_update['year']== 2018] = 2\n",
    "\n",
    "\n",
    "#test\n",
    "test_data['year'][test_data['year']==2016] = 0\n",
    "test_data['year'][test_data['year'] == 2017] = 1\n",
    "test_data['year'][test_data['year']== 2018] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8735"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_update['uniqueid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['bank_account'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_update['bank_account'][train_update['bank_account']=='No'] = 0\n",
    "train_update['bank_account'][train_update['bank_account']=='Yes'] = 1\n",
    "\n",
    "\n",
    "\n",
    "target = train_update['bank_account']\n",
    "train_update = train_update.drop('bank_account', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "Name: bank_account, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23524 entries, 0 to 23523\n",
      "Data columns (total 15 columns):\n",
      "year                      23524 non-null int64\n",
      "uniqueid                  23524 non-null object\n",
      "location_type             23524 non-null object\n",
      "cellphone_access          23524 non-null object\n",
      "household_size            23524 non-null int64\n",
      "age_of_respondent         23524 non-null int64\n",
      "gender_of_respondent      23524 non-null object\n",
      "relationship_with_head    23524 non-null object\n",
      "marital_status            23524 non-null object\n",
      "education_level           23524 non-null object\n",
      "job_type                  23524 non-null object\n",
      "country_Kenya             23524 non-null uint8\n",
      "country_Rwanda            23524 non-null uint8\n",
      "country_Tanzania          23524 non-null uint8\n",
      "country_Uganda            23524 non-null uint8\n",
      "dtypes: int64(3), object(8), uint8(4)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rural', 'Urban'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['location_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_update['location_type'][train_update['location_type'] == 'Urban'] = 1\n",
    "train_update['location_type'][train_update['location_type'] == 'Rural'] = 0\n",
    "\n",
    "test_data['location_type'][test_data['location_type'] == 'Urban'] = 1\n",
    "test_data['location_type'][test_data['location_type'] == 'Rural'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['cellphone_access'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_update['cellphone_access'][train_update['cellphone_access']=='Yes'] = 1\n",
    "train_update['cellphone_access'][train_update['cellphone_access'] == 'No'] = 0\n",
    "\n",
    "test_data['cellphone_access'][test_data['cellphone_access']=='Yes'] = 1\n",
    "test_data['cellphone_access'][test_data['cellphone_access'] == 'No'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['gender_of_respondent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_update = pd.get_dummies(train_update, columns = ['gender_of_respondent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23524 entries, 0 to 23523\n",
      "Data columns (total 16 columns):\n",
      "year                           23524 non-null int64\n",
      "uniqueid                       23524 non-null object\n",
      "location_type                  23524 non-null object\n",
      "cellphone_access               23524 non-null object\n",
      "household_size                 23524 non-null int64\n",
      "age_of_respondent              23524 non-null int64\n",
      "relationship_with_head         23524 non-null object\n",
      "marital_status                 23524 non-null object\n",
      "education_level                23524 non-null object\n",
      "job_type                       23524 non-null object\n",
      "country_Kenya                  23524 non-null uint8\n",
      "country_Rwanda                 23524 non-null uint8\n",
      "country_Tanzania               23524 non-null uint8\n",
      "country_Uganda                 23524 non-null uint8\n",
      "gender_of_respondent_Female    23524 non-null uint8\n",
      "gender_of_respondent_Male      23524 non-null uint8\n",
      "dtypes: int64(3), object(7), uint8(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Child', 'Head of Household', 'Other non-relatives',\n",
       "       'Other relative', 'Parent', 'Spouse'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['relationship_with_head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_update =pd.get_dummies(train_update, columns = ['relationship_with_head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data =pd.get_dummies(test_data, columns = ['relationship_with_head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Divorced/Seperated', 'Dont know', 'Married/Living together',\n",
       "       'Single/Never Married', 'Widowed'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['marital_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_update['marital_status'].value_counts()\n",
    "train_data = train_update.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customer_id = train_data['uniqueid']\n",
    "\n",
    "unique_copy = train_data.copy()\n",
    "train_update = unique_copy.drop('uniqueid', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_update['marital_status'][train_update['marital_status'] == 'Married/Living together'] = 0\n",
    "#train_update['marital_status'][train_update['marital_status'] == 'Single/Never Married'] = 1\n",
    "#train_update['marital_status'][train_update['marital_status'] == 'Widowed'] = 2\n",
    "#train_update['marital_status'][train_update['marital_status'] == 'Divorced/Separated'] = 3\n",
    "#train_update['marital_status'][train_update['marital_status'] == 'Dont know'] = 4\n",
    "\n",
    "marital_list = ['Married/Living together','Single/Never Married','Widowed','Divorced/Separated','Dont know']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for k in train_update.keys():\n",
    "    if k == 'marital_status' or 'education_level' or 'job_type':\n",
    "        lbl =  LabelEncoder()\n",
    "        lbl.fit(list(train_update[k].values))\n",
    "        train_update[k] = lbl.transform(list(train_update[k].values))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "marital_list = ['Married/Living together','Single/Never Married','Widowed','Divorced/Separated','Dont know']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for k in test_data.keys():\n",
    "    if k == 'marital_status' or 'education_level' or 'job_type':\n",
    "        lbl =  LabelEncoder()\n",
    "        lbl.fit(list(test_data[k].values))\n",
    "        test_data[k] = lbl.transform(list(test_data[k].values))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['marital_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['education_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_update['education_level'][train_update['education_level'] == 'Tertiary education'] = 0\n",
    "#train_update['education_level'][train_update['education_level'] == 'Secondary education'] = 1\n",
    "#train_update['education_level'][train_update['education_level'] == 'Primary education'] = 2\n",
    "#train_update['education_level'][train_update['education_level'] == 'No formal education'] = 3\n",
    "#train_update['education_level'][train_update['education_level'] == 'Vocational/Specialised training'] = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_update['job_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rain_update['job_type'][train_update['job_type'] == 'Formally employed Private'] = 0\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Formally employed Government'] = 1\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Self employed'] = 2\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Informally employed'] = 2\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Government Dependent'] = 2\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Other Income'] = 3\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Remittance Dependent'] = 3\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Farming and Fishing'] = 2\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Dont Know/Refuse to answer'] = 4\n",
    "#rain_update['job_type'][train_update['job_type'] == 'Other/Dont know/RTA'] = 4\n",
    "\n",
    "#rain_update['job_type'][train_update['job_type'] == 'No Income'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>country_Kenya</th>\n",
       "      <th>country_Rwanda</th>\n",
       "      <th>country_Tanzania</th>\n",
       "      <th>country_Uganda</th>\n",
       "      <th>gender_of_respondent_Female</th>\n",
       "      <th>gender_of_respondent_Male</th>\n",
       "      <th>relationship_with_head_Child</th>\n",
       "      <th>relationship_with_head_Head of Household</th>\n",
       "      <th>relationship_with_head_Other non-relatives</th>\n",
       "      <th>relationship_with_head_Other relative</th>\n",
       "      <th>relationship_with_head_Parent</th>\n",
       "      <th>relationship_with_head_Spouse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  location_type  cellphone_access  household_size  age_of_respondent  \\\n",
       "0     2              0                 1               2                  8   \n",
       "1     2              0                 0               4                 54   \n",
       "2     2              1                 1               4                 10   \n",
       "3     2              0                 1               4                 18   \n",
       "4     2              1                 0               7                 10   \n",
       "\n",
       "   marital_status  education_level  job_type  country_Kenya  country_Rwanda  \\\n",
       "0               2                3         9              1               0   \n",
       "1               4                0         4              1               0   \n",
       "2               3                5         9              1               0   \n",
       "3               2                2         3              1               0   \n",
       "4               3                2         5              1               0   \n",
       "\n",
       "   country_Tanzania  country_Uganda  gender_of_respondent_Female  \\\n",
       "0                 0               0                            1   \n",
       "1                 0               0                            1   \n",
       "2                 0               0                            0   \n",
       "3                 0               0                            1   \n",
       "4                 0               0                            0   \n",
       "\n",
       "   gender_of_respondent_Male  relationship_with_head_Child  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          1                             0   \n",
       "3                          0                             0   \n",
       "4                          1                             1   \n",
       "\n",
       "   relationship_with_head_Head of Household  \\\n",
       "0                                         0   \n",
       "1                                         1   \n",
       "2                                         0   \n",
       "3                                         1   \n",
       "4                                         0   \n",
       "\n",
       "   relationship_with_head_Other non-relatives  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   relationship_with_head_Other relative  relationship_with_head_Parent  \\\n",
       "0                                      0                              0   \n",
       "1                                      0                              0   \n",
       "2                                      1                              0   \n",
       "3                                      0                              0   \n",
       "4                                      0                              0   \n",
       "\n",
       "   relationship_with_head_Spouse  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_update.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_update.to_csv('UnScaled Data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target.to_csv('train_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "Name: bank_account, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "min_max = MinMaxScaler()\n",
    "\n",
    "train_split =std.fit_transform(train_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target = target.astype('int')\n",
    "x_train, x_test,y_train, y_test = train_test_split(train_split, target, train_size = 0.8, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18819, 20), (18819,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87560444231893297"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train, y_train)\n",
    "lr.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88119022316684381"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr.predict(x_test)\n",
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96918008395770228"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rand = RandomForestClassifier()\n",
    "rand.fit(x_train, y_train)\n",
    "rand.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86652497343251855"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rand = rand.predict(x_test)\n",
    "accuracy_score(predict_rand, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>bank_account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uniqueid_7867 x Kenya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uniqueid_6722 x Kenya</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniqueid_6714 x Kenya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uniqueid_8103 x Kenya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uniqueid_8657 x Kenya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                uniqueid  bank_account\n",
       "0  uniqueid_7867 x Kenya           1.0\n",
       "1  uniqueid_6722 x Kenya           0.0\n",
       "2  uniqueid_6714 x Kenya           1.0\n",
       "3  uniqueid_8103 x Kenya           1.0\n",
       "4  uniqueid_8657 x Kenya           1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SubmissionFile.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23524 entries, 0 to 23523\n",
      "Data columns (total 20 columns):\n",
      "year                                          23524 non-null int64\n",
      "location_type                                 23524 non-null int64\n",
      "cellphone_access                              23524 non-null int64\n",
      "household_size                                23524 non-null int64\n",
      "age_of_respondent                             23524 non-null int64\n",
      "marital_status                                23524 non-null int64\n",
      "education_level                               23524 non-null int64\n",
      "job_type                                      23524 non-null int64\n",
      "country_Kenya                                 23524 non-null int64\n",
      "country_Rwanda                                23524 non-null int64\n",
      "country_Tanzania                              23524 non-null int64\n",
      "country_Uganda                                23524 non-null int64\n",
      "gender_of_respondent_Female                   23524 non-null int64\n",
      "gender_of_respondent_Male                     23524 non-null int64\n",
      "relationship_with_head_Child                  23524 non-null int64\n",
      "relationship_with_head_Head of Household      23524 non-null int64\n",
      "relationship_with_head_Other non-relatives    23524 non-null int64\n",
      "relationship_with_head_Other relative         23524 non-null int64\n",
      "relationship_with_head_Parent                 23524 non-null int64\n",
      "relationship_with_head_Spouse                 23524 non-null int64\n",
      "dtypes: int64(20)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "train_update.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-8b905f0148bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-ca0342926f25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    864\u001b[0m                                  \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                                  \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_first\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                                  dtype=dtype)\n\u001b[0m\u001b[0;32m    867\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    872\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m     \u001b[1;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m     \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_factorize_from_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[1;32m--> 262\u001b[1;33m                                       raise_cast_failure=True)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "test_data = pd.get_dummies(test_data, columns = ['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-a6cbb57e521d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'gender_of_respondent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    864\u001b[0m                                  \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                                  \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_first\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                                  dtype=dtype)\n\u001b[0m\u001b[0;32m    867\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    872\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m     \u001b[1;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m     \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_factorize_from_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[1;32m--> 262\u001b[1;33m                                       raise_cast_failure=True)\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "test_data = pd.get_dummies(test_data, columns = ['gender_of_respondent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_id = test_data['uniqueid']\n",
    "test_data = test_data.drop('uniqueid', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23524, 20), (10086, 20))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_update.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.to_csv('UnScaled Data_test.csv')\n",
    "test_data = std.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = lr.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.20863498,  1.26021614,  0.57818983, ..., -0.31320077,\n",
       "        -1.17445083,  1.17445083],\n",
       "       [ 1.20863498,  1.26021614,  0.57818983, ..., -0.31320077,\n",
       "        -1.17445083,  1.17445083],\n",
       "       [ 1.20863498, -0.79351467, -1.72953578, ..., -0.31320077,\n",
       "         0.85146179, -0.85146179],\n",
       "       ..., \n",
       "       [ 1.20863498,  1.26021614,  0.57818983, ...,  3.19284021,\n",
       "        -1.17445083,  1.17445083],\n",
       "       [ 1.20863498, -0.79351467,  0.57818983, ...,  3.19284021,\n",
       "         0.85146179, -0.85146179],\n",
       "       [ 1.20863498,  1.26021614,  0.57818983, ...,  3.19284021,\n",
       "        -1.17445083,  1.17445083]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction = test_data\n",
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = test_prediction.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_conct = []\n",
    "for i, j in zip(test_country, test_id):\n",
    "    letter = str(j)+' x '+str(i)\n",
    "    target_conct.append(letter)\n",
    "    \n",
    "    \n",
    "target_array = np.array(target_conct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_target = {'uniqueid':target_array}\n",
    "dataframe = pd.DataFrame(dict_target)\n",
    "dataframe.to_csv('test_unique_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['uniqueid_6056 x Kenya', 'uniqueid_6060 x Kenya'], \n",
       "      dtype='<U24')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_array[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uniqueid', 'bank_account'], dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission_file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_submission = {'bank_account':test_prediction.astype('int'),'uniqueid':target_array}\n",
    "frame = pd.DataFrame(dict_submission)\n",
    "frame.to_csv('logistic_regression.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'uniqueid_7867 x Kenya' in target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank_account</th>\n",
       "      <th>uniqueid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>uniqueid_6056 x Kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>uniqueid_6060 x Kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>uniqueid_6065 x Kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>uniqueid_6072 x Kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>uniqueid_6073 x Kenya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bank_account               uniqueid\n",
       "0             0  uniqueid_6056 x Kenya\n",
       "1             1  uniqueid_6060 x Kenya\n",
       "2             0  uniqueid_6065 x Kenya\n",
       "3             0  uniqueid_6072 x Kenya\n",
       "4             0  uniqueid_6073 x Kenya"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>bank_account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uniqueid_6056 x Kenya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uniqueid_6060 x Kenya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniqueid_6065 x Kenya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uniqueid_6072 x Kenya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uniqueid_6073 x Kenya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                uniqueid  bank_account\n",
       "0  uniqueid_6056 x Kenya             0\n",
       "1  uniqueid_6060 x Kenya             1\n",
       "2  uniqueid_6065 x Kenya             0\n",
       "3  uniqueid_6072 x Kenya             0\n",
       "4  uniqueid_6073 x Kenya             0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['uniqueid'] = target_array\n",
    "test['bank_account'] = test_prediction.astype('int')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('logistic_regression.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8901168969181722"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier()\n",
    "gbrt.fit(x_train, y_train)\n",
    "gbrt.score(x_train, y_train)\n",
    "\n",
    "\n",
    "pred = gbrt.predict(x_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = gbrt.predict(final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['uniqueid'] = target_array\n",
    "test['bank_account'] =pred.astype('int')\n",
    "\n",
    "test.to_csv('gbrt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>bank_account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uniqueid_6056 x Kenya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uniqueid_6060 x Kenya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniqueid_6065 x Kenya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uniqueid_6072 x Kenya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uniqueid_6073 x Kenya</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                uniqueid  bank_account\n",
       "0  uniqueid_6056 x Kenya             1\n",
       "1  uniqueid_6060 x Kenya             1\n",
       "2  uniqueid_6065 x Kenya             0\n",
       "3  uniqueid_6072 x Kenya             0\n",
       "4  uniqueid_6073 x Kenya             0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 384 out of 384 | elapsed:   38.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.828589831631\n",
      "Best Params:  {'C': 1, 'class_weight': {1: 0.7, 0: 0.3}, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
    "solver = ['liblinear', 'saga']\n",
    "\n",
    "param_grid = dict(penalty=penalty,\n",
    "                  C=C,\n",
    "                  class_weight=class_weight,\n",
    "                  solver=solver)\n",
    "\n",
    "grid = GridSearchCV(estimator=lr,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='roc_auc',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   34.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.861917076996\n",
      "Best Params:  {'learning_rate': 0.1, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier()\n",
    "learning_rate = [0.1,1, 10]\n",
    "\n",
    "n_estimators = [100,200,400]\n",
    "\n",
    "param_grid = dict(learning_rate = learning_rate,\n",
    "                 n_estimators = n_estimators)\n",
    "\n",
    "grid = GridSearchCV(estimator=gbrt,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='roc_auc',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89228970721079759, 0.8928799149840595)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(learning_rate = 0.1, n_estimators = 200)\n",
    "gbrt.fit(x_train, y_train)\n",
    "gbrt.score(x_train, y_train),gbrt.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = gbrt.predict(final_prediction)\n",
    "test = pd.DataFrame()\n",
    "test['uniqueid'] = target_array\n",
    "test['bank_account'] =pred.astype('int')\n",
    "\n",
    "test.to_csv('gbrt_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001FC33402DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\E...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001FC33402DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\E...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 9, 6, 19, 9, 38, 43118, tzinfo=datetime.timezone.utc), 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'session': 'B5FE645D68284E6C8BFC0FEBDCAC6C9C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'B5FE645D68284E6C8BFC0FEBDCAC6C9C']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 9, 6, 19, 9, 38, 43118, tzinfo=datetime.timezone.utc), 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'session': 'B5FE645D68284E6C8BFC0FEBDCAC6C9C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'B5FE645D68284E6C8BFC0FEBDCAC6C9C'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 9, 6, 19, 9, 38, 43118, tzinfo=datetime.timezone.utc), 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'session': 'B5FE645D68284E6C8BFC0FEBDCAC6C9C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-86-0b670cb9691a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1fc3d4c49b0, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001FC3D152E40, file \"<ipython-input-86-0b670cb9691a>\", line 21>\n        result = <ExecutionResult object at 1fc3d4c49b0, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001FC3D152E40, file \"<ipython-input-86-0b670cb9691a>\", line 21>, result=<ExecutionResult object at 1fc3d4c49b0, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001FC3D152E40, file \"<ipython-input-86-0b670cb9691a>\", line 21>\n        self.user_global_ns = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma...import warnings\\nwarnings.filterwarnings('ignore')\", \"train_data = pd.read_csv('Train_v2.csv')\\ntest_da...bmission_file = pd.read_csv('SubmissionFile.csv')\", \"country = train_data['country']\\ntest_country = test_data['country']\\n\\ntest_id = test_data['uniqueid']\", 'Submission_file.head()', 'test_data.info()', 'train_data.head()', 'train_data.info()', \"np.unique(train_data['country'])\", \"train_update = pd.get_dummies(train_data, column... pd.get_dummies(test_data, columns = ['country'])\", 'train_update.info()', \"np.unique(train_update['year'])\", \"#train\\ntrain_update['year'][train_update['year']...1\\ntest_data['year'][test_data['year']== 2018] = 2\", \"np.unique(train_update['year'])\", \"len(np.unique(train_update['uniqueid']))\", \"np.unique(train_update['bank_account'])\", \"train_update['bank_account'][train_update['bank_...ate = train_update.drop('bank_account', axis = 1)\", 'target[:2]', 'train_update.info()', \"np.unique(train_update['location_type'])\", ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:                 uniqueid  bank_account\n0  unique...       1.0\n4  uniqueid_8657 x Kenya           1.0, 6:   country  year    uniqueid bank_account locatio...   Primary education        Informally employed  , 8: array(['Kenya', 'Rwanda', 'Tanzania', 'Uganda'], dtype=object), 11: array([2016, 2017, 2018], dtype=int64), 13: array([0, 1, 2], dtype=int64), 14: 8735, 15: array(['No', 'Yes'], dtype=object), 17: 0    1\n1    0\nName: bank_account, dtype: object, 19: array(['Rural', 'Urban'], dtype=object), 21: array(['No', 'Yes'], dtype=object), ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        self.user_ns = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma...import warnings\\nwarnings.filterwarnings('ignore')\", \"train_data = pd.read_csv('Train_v2.csv')\\ntest_da...bmission_file = pd.read_csv('SubmissionFile.csv')\", \"country = train_data['country']\\ntest_country = test_data['country']\\n\\ntest_id = test_data['uniqueid']\", 'Submission_file.head()', 'test_data.info()', 'train_data.head()', 'train_data.info()', \"np.unique(train_data['country'])\", \"train_update = pd.get_dummies(train_data, column... pd.get_dummies(test_data, columns = ['country'])\", 'train_update.info()', \"np.unique(train_update['year'])\", \"#train\\ntrain_update['year'][train_update['year']...1\\ntest_data['year'][test_data['year']== 2018] = 2\", \"np.unique(train_update['year'])\", \"len(np.unique(train_update['uniqueid']))\", \"np.unique(train_update['bank_account'])\", \"train_update['bank_account'][train_update['bank_...ate = train_update.drop('bank_account', axis = 1)\", 'target[:2]', 'train_update.info()', \"np.unique(train_update['location_type'])\", ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:                 uniqueid  bank_account\n0  unique...       1.0\n4  uniqueid_8657 x Kenya           1.0, 6:   country  year    uniqueid bank_account locatio...   Primary education        Informally employed  , 8: array(['Kenya', 'Rwanda', 'Tanzania', 'Uganda'], dtype=object), 11: array([2016, 2017, 2018], dtype=int64), 13: array([0, 1, 2], dtype=int64), 14: 8735, 15: array(['No', 'Yes'], dtype=object), 17: 0    1\n1    0\nName: bank_account, dtype: object, 19: array(['Rural', 'Urban'], dtype=object), 21: array(['No', 'Yes'], dtype=object), ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Elishama\\Desktop\\AI Tunisia Hackathon\\<ipython-input-86-0b670cb9691a> in <module>()\n     16 random = RandomizedSearchCV(estimator=sgd,\n     17                             param_distributions=param_distributions,\n     18                             scoring='roc_auc',\n     19                             verbose=1, n_jobs=-1,\n     20                             n_iter=10)\n---> 21 random_result = random.fit(x_train, y_train)\n     22 \n     23 print('Best Score: ', random_result.best_score_)\n     24 print('Best Params: ', random_result.best_params_)\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=None, error_score='raise',...n_train_score=True, scoring='roc_auc', verbose=1), X=array([[-1.15175136,  1.24989924,  0.58972136, .... -0.17095748,\n        -0.22000008, -0.61922467]]), y=12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-1.15175136,  1.24989924,  0.58972136, .... -0.17095748,\n        -0.22000008, -0.61922467]])\n        y = 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Sep  6 20:09:40 2019\nPID: 7940              Python 3.6.8: C:\\Users\\Elishama\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), array([   0,    1,    2, ..., 6287, 6292, 6303]), 1, {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), array([   0,    1,    2, ..., 6287, 6292, 6303]), 1, {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), X=memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), y=12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), test=array([   0,    1,    2, ..., 6287, 6292, 6303]), verbose=1, parameters={'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        parameters = {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'})\n     91 \n     92         self._validate_params()\n     93 \n     94     def set_params(self, *args, **kwargs):\n     95         super(BaseSGD, self).set_params(*args, **kwargs)\n---> 96         self._validate_params()\n        self._validate_params = <bound method BaseSGD._validate_params of SGDCla...fle=True, tol=None, verbose=0, warm_start=False)>\n     97         return self\n     98 \n     99     @abstractmethod\n    100     def fit(self, X, y):\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _validate_params(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False))\n    118                              \"learning_rate is 'optimal'. alpha is used \"\n    119                              \"to compute the optimal learning rate.\")\n    120 \n    121         # raises ValueError if not registered\n    122         self._get_penalty_type(self.penalty)\n--> 123         self._get_learning_rate_type(self.learning_rate)\n        self._get_learning_rate_type = <bound method BaseSGD._get_learning_rate_type of...fle=True, tol=None, verbose=0, warm_start=False)>\n        self.learning_rate = 'adaptive'\n    124 \n    125         if self.loss not in self.loss_functions:\n    126             raise ValueError(\"The loss %s is not supported. \" % self.loss)\n    127 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _get_learning_rate_type(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), learning_rate='adaptive')\n    140     def _get_learning_rate_type(self, learning_rate):\n    141         try:\n    142             return LEARNING_RATE_TYPES[learning_rate]\n    143         except KeyError:\n    144             raise ValueError(\"learning rate %s \"\n--> 145                              \"is not supported. \" % learning_rate)\n        learning_rate = 'adaptive'\n    146 \n    147     def _get_penalty_type(self, penalty):\n    148         penalty = str(penalty).lower()\n    149         try:\n\nValueError: learning rate adaptive is not supported. \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\", line 142, in _get_learning_rate_type\n    return LEARNING_RATE_TYPES[learning_rate]\nKeyError: 'adaptive'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 423, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\", line 96, in set_params\n    self._validate_params()\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\", line 123, in _validate_params\n    self._get_learning_rate_type(self.learning_rate)\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\", line 145, in _get_learning_rate_type\n    \"is not supported. \" % learning_rate)\nValueError: learning rate adaptive is not supported. \n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Sep  6 20:09:40 2019\nPID: 7940              Python 3.6.8: C:\\Users\\Elishama\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), array([   0,    1,    2, ..., 6287, 6292, 6303]), 1, {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), array([   0,    1,    2, ..., 6287, 6292, 6303]), 1, {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), X=memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), y=12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), test=array([   0,    1,    2, ..., 6287, 6292, 6303]), verbose=1, parameters={'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        parameters = {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'})\n     91 \n     92         self._validate_params()\n     93 \n     94     def set_params(self, *args, **kwargs):\n     95         super(BaseSGD, self).set_params(*args, **kwargs)\n---> 96         self._validate_params()\n        self._validate_params = <bound method BaseSGD._validate_params of SGDCla...fle=True, tol=None, verbose=0, warm_start=False)>\n     97         return self\n     98 \n     99     @abstractmethod\n    100     def fit(self, X, y):\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _validate_params(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False))\n    118                              \"learning_rate is 'optimal'. alpha is used \"\n    119                              \"to compute the optimal learning rate.\")\n    120 \n    121         # raises ValueError if not registered\n    122         self._get_penalty_type(self.penalty)\n--> 123         self._get_learning_rate_type(self.learning_rate)\n        self._get_learning_rate_type = <bound method BaseSGD._get_learning_rate_type of...fle=True, tol=None, verbose=0, warm_start=False)>\n        self.learning_rate = 'adaptive'\n    124 \n    125         if self.loss not in self.loss_functions:\n    126             raise ValueError(\"The loss %s is not supported. \" % self.loss)\n    127 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _get_learning_rate_type(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), learning_rate='adaptive')\n    140     def _get_learning_rate_type(self, learning_rate):\n    141         try:\n    142             return LEARNING_RATE_TYPES[learning_rate]\n    143         except KeyError:\n    144             raise ValueError(\"learning rate %s \"\n--> 145                              \"is not supported. \" % learning_rate)\n        learning_rate = 'adaptive'\n    146 \n    147     def _get_penalty_type(self, penalty):\n    148         penalty = str(penalty).lower()\n    149         try:\n\nValueError: learning rate adaptive is not supported. \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Sep  6 20:09:40 2019\nPID: 7940              Python 3.6.8: C:\\Users\\Elishama\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), array([   0,    1,    2, ..., 6287, 6292, 6303]), 1, {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), array([   0,    1,    2, ..., 6287, 6292, 6303]), 1, {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), X=memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), y=12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), test=array([   0,    1,    2, ..., 6287, 6292, 6303]), verbose=1, parameters={'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        parameters = {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'})\n     91 \n     92         self._validate_params()\n     93 \n     94     def set_params(self, *args, **kwargs):\n     95         super(BaseSGD, self).set_params(*args, **kwargs)\n---> 96         self._validate_params()\n        self._validate_params = <bound method BaseSGD._validate_params of SGDCla...fle=True, tol=None, verbose=0, warm_start=False)>\n     97         return self\n     98 \n     99     @abstractmethod\n    100     def fit(self, X, y):\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _validate_params(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False))\n    118                              \"learning_rate is 'optimal'. alpha is used \"\n    119                              \"to compute the optimal learning rate.\")\n    120 \n    121         # raises ValueError if not registered\n    122         self._get_penalty_type(self.penalty)\n--> 123         self._get_learning_rate_type(self.learning_rate)\n        self._get_learning_rate_type = <bound method BaseSGD._get_learning_rate_type of...fle=True, tol=None, verbose=0, warm_start=False)>\n        self.learning_rate = 'adaptive'\n    124 \n    125         if self.loss not in self.loss_functions:\n    126             raise ValueError(\"The loss %s is not supported. \" % self.loss)\n    127 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _get_learning_rate_type(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), learning_rate='adaptive')\n    140     def _get_learning_rate_type(self, learning_rate):\n    141         try:\n    142             return LEARNING_RATE_TYPES[learning_rate]\n    143         except KeyError:\n    144             raise ValueError(\"learning rate %s \"\n--> 145                              \"is not supported. \" % learning_rate)\n        learning_rate = 'adaptive'\n    146 \n    147     def _get_penalty_type(self, penalty):\n    148         penalty = str(penalty).lower()\n    149         try:\n\nValueError: learning rate adaptive is not supported. \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-0b670cb9691a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                             n_iter=10)\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mrandom_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best Score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001FC33402DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\E...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001FC33402DB0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\E...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 9, 6, 19, 9, 38, 43118, tzinfo=datetime.timezone.utc), 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'session': 'B5FE645D68284E6C8BFC0FEBDCAC6C9C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'B5FE645D68284E6C8BFC0FEBDCAC6C9C']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 9, 6, 19, 9, 38, 43118, tzinfo=datetime.timezone.utc), 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'session': 'B5FE645D68284E6C8BFC0FEBDCAC6C9C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'B5FE645D68284E6C8BFC0FEBDCAC6C9C'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 9, 6, 19, 9, 38, 43118, tzinfo=datetime.timezone.utc), 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'session': 'B5FE645D68284E6C8BFC0FEBDCAC6C9C', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '70D1027C77FE46E189907BAD4A231B3B', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"\\nloss = ['hinge', 'log', 'modified_huber', 'squa...rint('Best Params: ', random_result.best_params_)\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-86-0b670cb9691a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1fc3d4c49b0, executio..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001FC3D152E40, file \"<ipython-input-86-0b670cb9691a>\", line 21>\n        result = <ExecutionResult object at 1fc3d4c49b0, executio..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001FC3D152E40, file \"<ipython-input-86-0b670cb9691a>\", line 21>, result=<ExecutionResult object at 1fc3d4c49b0, executio..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001FC3D152E40, file \"<ipython-input-86-0b670cb9691a>\", line 21>\n        self.user_global_ns = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma...import warnings\\nwarnings.filterwarnings('ignore')\", \"train_data = pd.read_csv('Train_v2.csv')\\ntest_da...bmission_file = pd.read_csv('SubmissionFile.csv')\", \"country = train_data['country']\\ntest_country = test_data['country']\\n\\ntest_id = test_data['uniqueid']\", 'Submission_file.head()', 'test_data.info()', 'train_data.head()', 'train_data.info()', \"np.unique(train_data['country'])\", \"train_update = pd.get_dummies(train_data, column... pd.get_dummies(test_data, columns = ['country'])\", 'train_update.info()', \"np.unique(train_update['year'])\", \"#train\\ntrain_update['year'][train_update['year']...1\\ntest_data['year'][test_data['year']== 2018] = 2\", \"np.unique(train_update['year'])\", \"len(np.unique(train_update['uniqueid']))\", \"np.unique(train_update['bank_account'])\", \"train_update['bank_account'][train_update['bank_...ate = train_update.drop('bank_account', axis = 1)\", 'target[:2]', 'train_update.info()', \"np.unique(train_update['location_type'])\", ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:                 uniqueid  bank_account\n0  unique...       1.0\n4  uniqueid_8657 x Kenya           1.0, 6:   country  year    uniqueid bank_account locatio...   Primary education        Informally employed  , 8: array(['Kenya', 'Rwanda', 'Tanzania', 'Uganda'], dtype=object), 11: array([2016, 2017, 2018], dtype=int64), 13: array([0, 1, 2], dtype=int64), 14: 8735, 15: array(['No', 'Yes'], dtype=object), 17: 0    1\n1    0\nName: bank_account, dtype: object, 19: array(['Rural', 'Urban'], dtype=object), 21: array(['No', 'Yes'], dtype=object), ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n        self.user_ns = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ma...import warnings\\nwarnings.filterwarnings('ignore')\", \"train_data = pd.read_csv('Train_v2.csv')\\ntest_da...bmission_file = pd.read_csv('SubmissionFile.csv')\", \"country = train_data['country']\\ntest_country = test_data['country']\\n\\ntest_id = test_data['uniqueid']\", 'Submission_file.head()', 'test_data.info()', 'train_data.head()', 'train_data.info()', \"np.unique(train_data['country'])\", \"train_update = pd.get_dummies(train_data, column... pd.get_dummies(test_data, columns = ['country'])\", 'train_update.info()', \"np.unique(train_update['year'])\", \"#train\\ntrain_update['year'][train_update['year']...1\\ntest_data['year'][test_data['year']== 2018] = 2\", \"np.unique(train_update['year'])\", \"len(np.unique(train_update['uniqueid']))\", \"np.unique(train_update['bank_account'])\", \"train_update['bank_account'][train_update['bank_...ate = train_update.drop('bank_account', axis = 1)\", 'target[:2]', 'train_update.info()', \"np.unique(train_update['location_type'])\", ...], 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {4:                 uniqueid  bank_account\n0  unique...       1.0\n4  uniqueid_8657 x Kenya           1.0, 6:   country  year    uniqueid bank_account locatio...   Primary education        Informally employed  , 8: array(['Kenya', 'Rwanda', 'Tanzania', 'Uganda'], dtype=object), 11: array([2016, 2017, 2018], dtype=int64), 13: array([0, 1, 2], dtype=int64), 14: 8735, 15: array(['No', 'Yes'], dtype=object), 17: 0    1\n1    0\nName: bank_account, dtype: object, 19: array(['Rural', 'Urban'], dtype=object), 21: array(['No', 'Yes'], dtype=object), ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Elishama\\Desktop\\AI Tunisia Hackathon\\<ipython-input-86-0b670cb9691a> in <module>()\n     16 random = RandomizedSearchCV(estimator=sgd,\n     17                             param_distributions=param_distributions,\n     18                             scoring='roc_auc',\n     19                             verbose=1, n_jobs=-1,\n     20                             n_iter=10)\n---> 21 random_result = random.fit(x_train, y_train)\n     22 \n     23 print('Best Score: ', random_result.best_score_)\n     24 print('Best Params: ', random_result.best_params_)\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=None, error_score='raise',...n_train_score=True, scoring='roc_auc', verbose=1), X=array([[-1.15175136,  1.24989924,  0.58972136, .... -0.17095748,\n        -0.22000008, -0.61922467]]), y=12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-1.15175136,  1.24989924,  0.58972136, .... -0.17095748,\n        -0.22000008, -0.61922467]])\n        y = 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Sep  6 20:09:40 2019\nPID: 7940              Python 3.6.8: C:\\Users\\Elishama\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), array([   0,    1,    2, ..., 6287, 6292, 6303]), 1, {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), 12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), array([   0,    1,    2, ..., 6287, 6292, 6303]), 1, {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), X=memmap([[-1.15175136,  1.24989924,  0.58972136, ...-0.17095748,\n         -0.22000008, -0.61922467]]), y=12033    0\n11888    0\n20909    0\n22785    0\n1432...0\nName: bank_account, Length: 18819, dtype: int32, scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([ 6266,  6267,  6268, ..., 18816, 18817, 18818]), test=array([   0,    1,    2, ..., 6287, 6292, 6303]), verbose=1, parameters={'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    418                       for k, v in fit_params.items()])\n    419 \n    420     test_scores = {}\n    421     train_scores = {}\n    422     if parameters is not None:\n--> 423         estimator.set_params(**parameters)\n        estimator.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        parameters = {'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'}\n    424 \n    425     start_time = time.time()\n    426 \n    427     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'alpha': 1, 'class_weight': {0: 0.5, 1: 0.5}, 'eta0': 100, 'learning_rate': 'adaptive', 'loss': 'log', 'penalty': 'l1'})\n     91 \n     92         self._validate_params()\n     93 \n     94     def set_params(self, *args, **kwargs):\n     95         super(BaseSGD, self).set_params(*args, **kwargs)\n---> 96         self._validate_params()\n        self._validate_params = <bound method BaseSGD._validate_params of SGDCla...fle=True, tol=None, verbose=0, warm_start=False)>\n     97         return self\n     98 \n     99     @abstractmethod\n    100     def fit(self, X, y):\n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _validate_params(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False))\n    118                              \"learning_rate is 'optimal'. alpha is used \"\n    119                              \"to compute the optimal learning rate.\")\n    120 \n    121         # raises ValueError if not registered\n    122         self._get_penalty_type(self.penalty)\n--> 123         self._get_learning_rate_type(self.learning_rate)\n        self._get_learning_rate_type = <bound method BaseSGD._get_learning_rate_type of...fle=True, tol=None, verbose=0, warm_start=False)>\n        self.learning_rate = 'adaptive'\n    124 \n    125         if self.loss not in self.loss_functions:\n    126             raise ValueError(\"The loss %s is not supported. \" % self.loss)\n    127 \n\n...........................................................................\nC:\\Users\\Elishama\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in _get_learning_rate_type(self=SGDClassifier(alpha=1, average=False, class_weig...ffle=True, tol=None, verbose=0, warm_start=False), learning_rate='adaptive')\n    140     def _get_learning_rate_type(self, learning_rate):\n    141         try:\n    142             return LEARNING_RATE_TYPES[learning_rate]\n    143         except KeyError:\n    144             raise ValueError(\"learning rate %s \"\n--> 145                              \"is not supported. \" % learning_rate)\n        learning_rate = 'adaptive'\n    146 \n    147     def _get_penalty_type(self, penalty):\n    148         penalty = str(penalty).lower()\n    149         try:\n\nValueError: learning rate adaptive is not supported. \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive']\n",
    "class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
    "eta0 = [1, 10, 100]\n",
    "\n",
    "param_distributions = dict(loss=loss,\n",
    "                           penalty=penalty,\n",
    "                           alpha=alpha,\n",
    "                           learning_rate=learning_rate,\n",
    "                           class_weight=class_weight,\n",
    "                           eta0=eta0)\n",
    "\n",
    "random = RandomizedSearchCV(estimator=sgd,\n",
    "                            param_distributions=param_distributions,\n",
    "                            scoring='roc_auc',\n",
    "                            verbose=1, n_jobs=-1,\n",
    "                            n_iter=10)\n",
    "random_result = random.fit(x_train, y_train)\n",
    "\n",
    "print('Best Score: ', random_result.best_score_)\n",
    "print('Best Params: ', random_result.best_params_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
